{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Medical_Image_Regsitration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x6HaLO5rCf9",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Medical Image Registration using Deep Neural Networks, using DeepReg\n",
        "\n",
        "### Authors, Acknowledgements etc etc\n",
        "\n",
        "# Table of Contents\n",
        "1. [Set-up](#setup)\n",
        "2. [Introduction to Registration](#IntroReg)\n",
        "3. [Registration with Deep Learning](#DeepRegistrationIntro)\n",
        "4. [A simple non-rigid registration using Deep Learning](#third-example)\n",
        "5. [MIR using a DNN](#fourth_example)\n",
        "6. [References](#references)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey3CnrZuBtCi",
        "colab_type": "text"
      },
      "source": [
        "# Objective\n",
        "This tutorial introduces a new open-source project [DeepReg](https://github.com/DeepRegNet/DeepReg), which is designed to be a rookie-friendly package for researchers interested in image registration using deep learning. \n",
        "\n",
        "A previous MICCAI workshop [learn2reg](https://learn2reg.github.io/) provided an excelent example of novel algorithms and interesting approaches in this active research area, whilst this tutorial explores the strenghth of the simple, yet generalisable deisgn of DeepReg. \n",
        "- Explain basic concepts in medical image registration (which can also be readily implemented using DeepReg!);\n",
        "- Explore the links between the classical iterative algorithms and modern algorithms using neural networks;\n",
        "- Perhaps more importantly, introduce the versatile capability of DeepReg, with diverse examples in real clinical challenges.\n",
        "\n",
        "All of this will require minimum coding expereince with DeepReg, accomanying a set of well-written documentation and a growing number of demos using real, open-accesible clinical data. This tutorial will get you started with a number of examples by step-by-step instructions.\n",
        "\n",
        "# Set-up <a name=\"setup\"></a>\n",
        "This tutorial uses DeepReg, which in turn has external dependencies which are managed by `pip`. \n",
        "\n",
        "To ensure the demo'd algorithms can run from this Google Colab notebook, you will need to mount your Google Drive and clone the repository into it. You can do this by running the following commands.\n",
        "\n",
        "You can also follow along in a local copy of the repo - in this case, follow instructions for set up at **Link to local setup instructions**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBep99T7DMvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "! pwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLZnPHlqZM9R",
        "colab_type": "text"
      },
      "source": [
        "Once the drive is mounted, ensure that you have GPU enabled for more efficient training. To do this, go to the Edit on the upper left hand bar:\n",
        "Edit -> Click on Notebook Settings -> Enable GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oedTHyNoDWzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# Make a directory in your google drive namde \"MICCAI_2020_reg_tutorial\"\n",
        "if not os.path.exists(\"./MICCAI_2020_reg_tutorial\"):\n",
        "  os.makedirs(\"./MICCAI_2020_reg_tutorial\")\n",
        "# Move into the dir\n",
        "%cd ./MICCAI_2020_reg_tutorial\n",
        "! pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMVBQEKnrNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the DeepReg repository which contains the code\n",
        "! git clone https://github.com/DeepRegNet/DeepReg.git\n",
        "%cd ./DeepReg/\n",
        "# pip install into the notebook env\n",
        "! pip install -e .\n",
        "! pip install wget\n",
        "! pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn1IiKXOrpmJ",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Registration <a name=\"IntroReg\"></a>\n",
        "\n",
        "Image registration is an essential process in many clinical applications and computer assisted interventions **cite**. Applications of medical image registration include - but are not limited to:\n",
        "* Longitudinal comparison of images for a given patient with the same imaging modality: for example, comparing the outcome of given cancer treatment in a patients' CT scans over time. **cite**\n",
        "* Inter-subject comparison: for example, population study using neuroimaging. **cite**\n",
        "* Multi-modal registration for image guided surgery: for example, aligning real-time ultrasound scans to pre-operative CT or MRI scans to real-time achieve guidance in neurosurgical or abdominal applications. **cite**\n",
        "* Atlas-based image segmentation: alighing new images to those carefully segmented, such that the reference segmentations can be propagated to those new images. \n",
        "\n",
        "Image registration is the mapping of one image coordinate system to another, and can be sub-divided into rigid registrations and non-rigid registrations, depending on whether or not higher-dimesional tissue deformations is modelled as oppose to, for exmaple, a 6 degree-of-freedon rigid transformation.\n",
        "\n",
        "A key concept in image registration is correspondence, which specifies the mapping between all voxels from one image to those from another image. The correspondence can be represented by dense displacment field (DDF), defined as a set of displacement vectors for all pixels or voxels from one image - that is, by using these displacement vectors, one image can be \"warped\" to become more \"similar\" to another.\n",
        "\n",
        "## Classical registration methods\n",
        "Historically, the so-called classical algorithms pose registration as an optimisation problem between a given pair of moving and fixed images. In these methods, a pre-defined transformation model, rigid or nonrigid, is iteratively optimised to minimise a similarty measure - a metric that quantifies how \"similar\" between the warped moving image and the fixed image. \n",
        "\n",
        "The similarity measure can be a function sampling only important image features (extracted from a pre-processing step) or directly sampling all intensity values from both images.\n",
        "\n",
        "* **Feature-based registration**: For example, a transformation between point clouds - a type of features widely used in many applications - can be estimated using Iterative Closest Point (ICP) **cite**. The basis of ICP is to iteratively minimise the L2 distance between the two point clouds, estimating a transformation from the found correspondence, applying the transformation, and repeating the process until convergece reached.\n",
        "* **Intensity-based registration**: Cross correlation, mutual information and simple sum-square-difference in inresnity are all examples of useful similarity measures that can directly sample and measure difference between two images. These intensity-based algorithms can optimise a transformation model directly using images without the feature extraction step.\n",
        "\n",
        "Classical registration algorithms are a subject of research for the last two decades. Many today's deep-learning-based methods have been heavily influnced and derived from these prior work. (You can cite Dave's book here)\n",
        "\n",
        "## Why use deep learning for registration?\n",
        "First, the iterative classical registration algorthms are generally computationally very demanding, especially for 3D nonrigid registration. State-of-the-art classical methods are implemented on GPU still struggle for real-time performance for many time-critical clinical applications.\n",
        "\n",
        "Second, classical algorithms are inherently pairwise approaches that can not take into account population data statistics directly and relying on well-designed transformation models and valid similarity being avaialble and robust, challenging for many real-world tasks.\n",
        "\n",
        "However, it is important to point out that a) many deep-learning-based methods are still subjec to these limitations, especially those borrowed transformation models and similarity measures directly from the classical methods; b) classical algorithms have been refined for many clinical applications and still worked really well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRbUdZjq0_A",
        "colab_type": "text"
      },
      "source": [
        "# Image Registration with Deep Learning <a name=\"DeepRegistrationIntro\"></a>\n",
        "\n",
        "In recent years, image registration has been re-formulated as a learning problem, in which, pairs of moving and fixed images are passed to a machine learning model (usually a neural network nowadays) to predict a transformation between the images.\n",
        "\n",
        "In this tutorial, we investigate three factors that determine a deep learning approach for image registration:\n",
        "\n",
        "1. What type of transformation is one trying to predict?\n",
        "2. What type image data are being registered? Are there any other data, such as segmentations, to support the registration?\n",
        "3. Are the data paired? Are they labeled?\n",
        "\n",
        "## Types of transformations\n",
        "\n",
        "- **Predicting a dense displacement field**\n",
        "\n",
        "  Given a pair of moving and fixed images, a registration network\n",
        "  can be trained to output dense displacement field (DDF) of the same shape as the moving image. Each value in the DDF\n",
        "  can be considered as the placement of the corresponding pixel / voxel of the moving\n",
        "  image. Therefore, the DDF defines a mapping from the moving image's coordinates to the\n",
        "  fixed image.\n",
        "\n",
        "  In this tutorial, we mainly focus on DDF-based methods.\n",
        "\n",
        "- **Predict a dense velocity field**\n",
        "\n",
        "  Another option is to predict a dense velocity field (DVF) between a pair of images, such that a diffeomorphic\n",
        "  DDF can be numerically integrated. Read\n",
        "  [\"A fast diffeomorphic image registration algorithm\"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.474.1033&rep=rep1&type=pdf)\n",
        "  for more details.\n",
        "\n",
        "- **Predict an affine transformation**\n",
        "\n",
        "  A more constrained option is to predict an affine transformation, parameterised the\n",
        "  affine transformation matrix of 12 degrees of freedom. The DDF can then be computed to\n",
        "  resample the moving images in fixed image space.\n",
        "\n",
        "- **Predict a region of interest**\n",
        "\n",
        "  Instead of outputting the transformation between coordinates, given moving image,\n",
        "  fixed image, and a region of interest (ROI) in the moving image, the network can\n",
        "  predict the ROI in fixed image directly. Interested readers are referred to the MICCAI\n",
        "  2019 paper:\n",
        "  [Conditional segmentation in lieu of image registration](https://arxiv.org/abs/1907.00438)\n",
        "\n",
        "\n",
        "## Data availability - level of supervision\n",
        "\n",
        "Depending on the availability of the data labels, registration networks can be trained\n",
        "with different approaches:\n",
        "\n",
        "### Unsupervised\n",
        "\n",
        "When the data label is unavailable, training can be achieved via an unsupervised loss.\n",
        "The\n",
        "following is an illustration of an unsupervised DDF-based registration network.\n",
        "\n",
        "![Unsupervised DDF-based registration network](asset/registration-ddf-nn-unsupervised.svg \":size=600\")\n",
        "\n",
        "The loss function often consists of the intensity based loss and deformation loss.\n",
        "\n",
        "### Weakly-supervised\n",
        "\n",
        "When there is no intensity based loss that is appropriate for the image pair one would\n",
        "like to register, the training can take a pair of corresponding moving and fixed labels\n",
        "(in addition to the image pair), represented by binary masks, to compute a label\n",
        "dissimilarity (feature based loss) to drive the registration.\n",
        "\n",
        "Combined with the regularisation on the predicted displacement field, this forms a\n",
        "weakly-supervised training. An illustration of an weakly-supervised DDF-based\n",
        "registration network is provided below.\n",
        "\n",
        "When multiple labels are available for each image, the labels can be sampled during\n",
        "training iteration, such that only one label per image is used in each iteration of the\n",
        "data set (epoch). Read [data sampling API](tutorial_sampling.md) for more details.\n",
        "\n",
        "![Weakly-supervised DDF-based registration network](asset/registration-ddf-nn-weakly-supervised.svg \":size=600\")\n",
        "\n",
        "### Combined\n",
        "\n",
        "When the data label is available, combining intensity based, feature based, and\n",
        "deformation based losses together has shown superior registration accuracy, compared to\n",
        "unsupervised and weakly supervised methods. Following is an illustration of a combined\n",
        "DDF-based registration network.\n",
        "\n",
        "![Combined DDF-based registration network](asset/registration-ddf-nn-combined.svg \":size=600\")\n",
        "\n",
        "## Losses - depend on supervision and the types of images!\n",
        "\n",
        "To train the deep registration network, measures of similarity between the input images and their transformations are mainly used:\n",
        "\n",
        "- **Intensity based (image based) loss**\n",
        "\n",
        "  This type of loss measures the dissimilarity of the fixed image and warped moving\n",
        "  image, which is adapted from the classical image registration methods. Intensity based\n",
        "  loss is modality-independent and similar to many other well-studied computer vision\n",
        "  and medical imaging tasks, such as image segmentation.\n",
        "\n",
        "  The common loss functions are normalized cross correlation (NCC), sum of squared\n",
        "  distance (SSD), and normalized mutual information (MI).\n",
        "\n",
        "- **Feature based (label based) loss**\n",
        "  Provided labels for the input images, a feature based loss may be used to measure the (dis)similarity of warped regions of interest. Having computed a transformation between images using the net, one of the labels is warped and compared to the ground truth image label.\n",
        " Labels are typically manually contoured organs.\n",
        "\n",
        "  The common loss function is Dice loss, Jacard and average cross-entropy over all\n",
        "  voxels, which are measures of the overlap of the ROIs. The loss will minimise the negative overlap measure (eg. l = 1 - dice_score) to maximise overlap of the regions during training.\n",
        "\n",
        "- **Deformation loss**\n",
        "  Additionally, training may be regularised by computing the \"likelihood\" of a given displacement field. High deformation losses point to very unlikely displacement due to high gradients of the field. For DDFs, typical regularisation losses are bending energy losses, L1 or L2 norms of the displacement gradients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC-lMrB4Ct_",
        "colab_type": "text"
      },
      "source": [
        "# Optimising a global transformation from a single pair of images - the classical registration algorithms\n",
        "\n",
        "We will define a single layer example using functions from DeepReg, and train it to register two images.\n",
        "\n",
        "This demo uses data from **where is this data from.**\n",
        "\n",
        "First, we will illustrate the possibility of \"self-registering\" an image to it's affine-transformed counterpart.\n",
        "\n",
        "[//]:# \"you might want to make it consistent as `deformation` is often refered to as a nonrigid subset of the general `transformation`\"\n",
        "\n",
        "Then, we will register two subjects' scans (inte-subject registration).\n",
        "\n",
        "## Learning an affine transformation: \"self-registration\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNdefjurAmQ",
        "colab_type": "code",
        "tags": [],
        "colab": {}
      },
      "source": [
        "# We import some utility modules.\n",
        "import nibabel\n",
        "import tensorflow as tf \n",
        "import deepreg.model.layer as layer\n",
        "import deepreg.model.loss.image as image_loss\n",
        "import deepreg.model.loss.deform as deform_loss\n",
        "import deepreg.model.layer_util as layer_util\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import h5py\n",
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhyT2kh6wO__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We download the data for this example.\n",
        "MAIN_PATH = os.getcwd()\n",
        "\n",
        "DATA_PATH = \"dataset\"\n",
        "if not os.path.exists(os.path.join(MAIN_PATH, DATA_PATH)):\n",
        "  os.makedirs(os.path.join(MAIN_PATH, DATA_PATH))\n",
        "\n",
        "FILE_PATH = os.path.abspath(os.path.join(MAIN_PATH, DATA_PATH, \"demo2.h5\"))\n",
        "ORIGIN = \"https://github.com/YipengHu/example-data/raw/master/promise12/demo2.h5\"\n",
        "\n",
        "get_file(FILE_PATH, ORIGIN)\n",
        "print(\"Prostate MR data downloaded: %s.\" % FILE_PATH)\n",
        "\n",
        "os.chdir(MAIN_PATH)\n",
        "\n",
        "DATA_PATH = \"dataset\"\n",
        "FILE_PATH = os.path.join(MAIN_PATH, DATA_PATH, \"demo2.h5\")\n",
        "\n",
        "fid = h5py.File(FILE_PATH, \"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TBdx9dDt41n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining some utility functions\n",
        "@tf.function\n",
        "def train_step(warper, weights, optimizer, mov, fix):\n",
        "    \"\"\"\n",
        "    Train step function for backpropagation using gradient tape\n",
        "\n",
        "    :param warper: warping function returned from layer.Warping\n",
        "    :param weights: trainable ddf [1, f_dim1, f_dim2, f_dim3, 3]\n",
        "    :param optimizer: tf.optimizers\n",
        "    :param mov: moving image [1, m_dim1, m_dim2, m_dim3]\n",
        "    :param fix: fixed image [1, f_dim1, f_dim2, f_dim3]\n",
        "    :return:\n",
        "        loss: overall loss to optimise\n",
        "        loss_image: image dissimilarity\n",
        "        loss_deform: deformation regularisation\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = warper(inputs=[weights, mov])\n",
        "        # Calculating the image loss between the ground truth and prediction\n",
        "        loss_image = image_loss.dissimilarity_fn(\n",
        "            y_true=fix, y_pred=pred, name=image_loss_name\n",
        "        )\n",
        "        # We calculate the deformation loss\n",
        "        loss_deform = deform_loss.local_displacement_energy(weights, deform_loss_name)\n",
        "        # Total loss is weighted\n",
        "        loss = loss_image + weight_deform_loss * loss_deform\n",
        "    # We calculate the gradients by backpropagating the loss to the trainable layer,\n",
        "    # which for registration is our ddf\n",
        "    gradients = tape.gradient(loss, [weights])\n",
        "    # Using our tf optimizer, we apply the gradients\n",
        "    optimizer.apply_gradients(zip(gradients, [weights]))\n",
        "    return loss, loss_image, loss_deform\n",
        "\n",
        "def plot_results(warping, var_ddf, moving_image, fixed_image):\n",
        "  \"\"\"\n",
        "  Plotting the results from training\n",
        "  :param warping: Warping layer instance\n",
        "  :param var_ddf: Trained DDF tensor [IM_SIZE_0, IM_SIZE_1, 3]\n",
        "  :param moving_image: [IM_SIZE_0, IM_SIZE_1, 3]\n",
        "  :param fixed_image:  [IM_SIZE_0, IM_SIZE_1, 3]\n",
        "  \"\"\"\n",
        "  warped_moving_image = warping(inputs=[var_ddf, moving_image])\n",
        "  # Display\n",
        "  idx_slices = [int(5 + x * 5) for x in range(int(fixed_image_size[3] / 5) - 1)]\n",
        "  nIdx = len(idx_slices)\n",
        "  plt.figure()\n",
        "  for idx in range(len(idx_slices)):\n",
        "      axs = plt.subplot(nIdx, 3, 3 * idx + 1)\n",
        "      axs.imshow(moving_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "      axs.axis(\"off\")\n",
        "      axs = plt.subplot(nIdx, 3, 3 * idx + 2)\n",
        "      axs.imshow(fixed_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "      axs.axis(\"off\")\n",
        "      axs = plt.subplot(nIdx, 3, 3 * idx + 3)\n",
        "      axs.imshow(warped_moving_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "      axs.axis(\"off\")\n",
        "  plt.ion()\n",
        "  plt.show()\n",
        "\n",
        "def display(moving_image, fixed_image):\n",
        "  \"\"\"\n",
        "  Displaying our two image tensors to register\n",
        "  :param moving_image: [IM_SIZE_0, IM_SIZE_1, 3]\n",
        "  :param fixed_image:  [IM_SIZE_0, IM_SIZE_1, 3]\n",
        "  \"\"\"\n",
        "  # Display\n",
        "  idx_slices = [int(5+x*5) for x in range(int(fixed_image_size[3]/5)-1)]\n",
        "  nIdx = len(idx_slices)\n",
        "  plt.figure()\n",
        "  for idx in range(len(idx_slices)):\n",
        "      axs = plt.subplot(nIdx, 2, 2*idx+1)\n",
        "      axs.imshow(moving_image[0,...,idx_slices[idx]], cmap='gray')\n",
        "      axs.axis('off')\n",
        "      axs = plt.subplot(nIdx, 2, 2*idx+2)\n",
        "      axs.imshow(fixed_image[0,...,idx_slices[idx]], cmap='gray')\n",
        "      axs.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mE6r_y4tAUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We define some registration parameters\n",
        "image_loss_name = \"lncc\" # local normalised cross correlation loss between images\n",
        "deform_loss_name = \"bending\" # Loss to measure the bending energy of the ddf\n",
        "weight_deform_loss = 1e3 # we weight the deformation loss\n",
        "learning_rate = 0.1\n",
        "total_iter = int(1000)\n",
        "initialiser = tf.random_normal_initializer(mean=0, stddev=1e-3)\n",
        "\n",
        "# We get an image from the dataset\n",
        "moving_image = tf.cast(tf.expand_dims(fid[\"image0\"], axis=0), dtype=tf.float32)\n",
        "\n",
        "# Apply a random affine-transformed to the image\n",
        "fixed_image_size = moving_image.shape\n",
        "# Generate a random transform that scales the image up by 40%\n",
        "random_transform = layer_util.random_transform_generator(batch_size=1, seed=1, scale=0.4)\n",
        "grid_ref = layer_util.get_reference_grid(grid_size=fixed_image_size[1:4])\n",
        "# We generate our \"paired\" fixed image by applying our random transform\n",
        "fixed_image = layer_util.resample(vol=moving_image, loc=layer_util.warp_grid(grid_ref, random_transform))\n",
        "\n",
        "display(moving_image, fixed_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW1zo7vxty9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Creating our DDF tensor that can be trained\n",
        "# The DDF will be of shape [IM_SIZE_1, IM_SIZE_2, 3],\n",
        "# representing the displacement field at each dimension.\n",
        "var_ddf = tf.Variable(initialiser(fixed_image_size + [3]), name=\"ddf\", trainable=True)\n",
        "\n",
        "# We create a warping layer and initialise an optimizer\n",
        "warping = layer.Warping(fixed_image_size=fixed_image_size[1:4])\n",
        "optimiser = tf.optimizers.Adam(learning_rate)\n",
        "\n",
        "## Training the layer\n",
        "## For this training, we are trying to predict the random transform generated.\n",
        "## With GPU this takes about 5 minutes.\n",
        "for step in range(total_iter):\n",
        "    # Call the gradient tape function\n",
        "    loss_opt, loss_image_opt, loss_deform_opt = train_step(\n",
        "        warping, var_ddf, optimiser, moving_image, fixed_image\n",
        "    )\n",
        "    if (step % 50) == 0:  # print info at every 50th step\n",
        "        tf.print(\n",
        "            \"Step\",\n",
        "            step,\n",
        "            \"loss\",\n",
        "            loss_opt,\n",
        "            image_loss_name,\n",
        "            loss_image_opt,\n",
        "            deform_loss_name,\n",
        "            loss_deform_opt,\n",
        "        )\n",
        "        # Visualising loss during training\n",
        "\n",
        "        # plt.figure()\n",
        "        # fig, axs = plt.subplots(1, 3)\n",
        "        # warped_moving_image = warping(inputs=[var_ddf, moving_image])\n",
        "        # axs[0].imshow(moving_image[0, ..., 12])\n",
        "        # axs[1].imshow(fixed_image[0, ..., 12])\n",
        "        # axs[2].imshow(warped_moving_image[0, ..., 12])\n",
        "        # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKp7U1yxwcrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the results\n",
        "plot_results(warping, var_ddf, moving_image, fixed_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWHNY4kYv_LM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Optimising an affine transformation: inter_subject registration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "OPKCDDULPT3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We define some registration parameters\n",
        "image_loss_name = \"lncc\" # local normalised cross correlation loss between images\n",
        "deform_loss_name = \"bending\" # Loss to measure the bending energy of the ddf\n",
        "weight_deform_loss = 1e3 # we weight the deformation loss\n",
        "learning_rate = 0.1\n",
        "total_iter = int(3000) # This will train for longer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNk5DbimPT3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We get our two subject images from our datasets\n",
        "moving_image = tf.cast(tf.expand_dims(fid[\"image0\"], axis=0), dtype=tf.float32)\n",
        "fixed_image = tf.cast(tf.expand_dims(fid[\"image1\"], axis=0), dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYo61smNPT30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We initialise our layers\n",
        "fixed_image_size = fixed_image.shape\n",
        "\n",
        "# Creating our DDF tensor that can be trained\n",
        "# The DDF will be of shape [IM_SIZE_1, IM_SIZE_2, 3],\n",
        "# representing the displacement field at each dimension.\n",
        "var_ddf = tf.Variable(initialiser(fixed_image_size + [3]), name=\"ddf\", trainable=True)\n",
        "\n",
        "# We create a warping layer and initialise an optimizer\n",
        "warping = layer.Warping(fixed_image_size=fixed_image_size[1:4])\n",
        "optimiser = tf.optimizers.Adam(learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "## Training the layer\n",
        "## With GPU this takes about 5 minutes.\n",
        "for step in range(total_iter):\n",
        "    # Call the gradient tape function\n",
        "    loss_opt, loss_image_opt, loss_deform_opt = train_step(\n",
        "        warping, var_ddf, optimiser, moving_image, fixed_image\n",
        "    )\n",
        "    if (step % 50) == 0:  # print info at every 50th step\n",
        "        tf.print(\n",
        "            \"Step\",\n",
        "            step,\n",
        "            \"loss\",\n",
        "            loss_opt,\n",
        "            image_loss_name,\n",
        "            loss_image_opt,\n",
        "            deform_loss_name,\n",
        "            loss_deform_opt,\n",
        "        )\n",
        "        # Visualising loss during training\n",
        "        # plt.figure()\n",
        "        # fig, axs = plt.subplots(1, 3)\n",
        "        # warped_moving_image = warping(inputs=[var_ddf, moving_image])\n",
        "        # axs[0].imshow(moving_image[0, ..., 12])\n",
        "        # axs[1].imshow(fixed_image[0, ..., 12])\n",
        "        # axs[2].imshow(warped_moving_image[0, ..., 12])\n",
        "        # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCBZ1DXHPT32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Warp the moving image using the optimised ddf and the warping layer.\n",
        "plot_results(warping, var_ddf, moving_image, fixed_image)\n",
        "\n",
        "## We can observe the effects of the warping on the moving label using the optimised affine transformation\n",
        "moving_label = tf.cast(tf.expand_dims(fid[\"label0\"], axis=0), dtype=tf.float32)\n",
        "fixed_label = tf.cast(tf.expand_dims(fid[\"label1\"], axis=0), dtype=tf.float32)\n",
        "\n",
        "plot_results(warping, var_ddf, moving_label, fixed_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dArjLUqbY_JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHX7HAbJe6Ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## predict\n",
        "warped_moving_image = warping(inputs=[var_ddf, moving_image])\n",
        "# Display\n",
        "idx_slices = [int(5 + x * 5) for x in range(int(fixed_image_size[3] / 5) - 1)]\n",
        "nIdx = len(idx_slices)\n",
        "plt.figure()\n",
        "for idx in range(len(idx_slices)):\n",
        "    axs = plt.subplot(nIdx, 3, 3 * idx + 1)\n",
        "    axs.imshow(moving_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "    axs.axis(\"off\")\n",
        "    axs = plt.subplot(nIdx, 3, 3 * idx + 2)\n",
        "    axs.imshow(fixed_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "    axs.axis(\"off\")\n",
        "    axs = plt.subplot(nIdx, 3, 3 * idx + 3)\n",
        "    axs.imshow(warped_moving_image[0, ..., idx_slices[idx]], cmap=\"gray\")\n",
        "    axs.axis(\"off\")\n",
        "plt.ion()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPAH2zDq4BjB",
        "colab_type": "text"
      },
      "source": [
        "# Medical Image registration using `DeepReg Demo`\n",
        "\n",
        "[//]:#\"i'm sort of hoping the DeepReg Demo becomes a thing ;)\"\n",
        "\n",
        "Now, we will build a more complex demo to investigate a clinical case.\n",
        "\n",
        "We will perform an inter-subject registration: aligning ct images from different patients. The images are all acquired at the same timepoint in the breathing cycle for all patients. This kind of registration is useful for determining how one stimulus affects multiple patietns. If a drug or invasive procedure is administered to multiple patients, registering the images from different patients can give medical professsionals a sense of how each patient is responding in comparison to others. An example of such an application can be seen in **[2]**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuxx6u164ABI",
        "colab_type": "text"
      },
      "source": [
        "The file IO is a bit more involved for this demo. We provide some function that do most of this for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODhxQ_Z1zfJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# if wget is installed remove the following line from comment\n",
        "import wget\n",
        "\n",
        "# if already in the abc/DeepReg directory then do nothing, otherwise\n",
        "# use os.chdir(r'abc/DeepReg') before this line\n",
        "main_path = os.getcwd()\n",
        "os.chdir(main_path)\n",
        "\n",
        "######## DOWNLOADING AND UNZIPPING ALL FILES INTO CORRECT PATH ########\n",
        "\n",
        "project_dir = r\"demos/unpaired_ct_lung\"\n",
        "os.chdir(project_dir)\n",
        "\n",
        "url = \"https://zenodo.org/record/3835682/files/training.zip\"\n",
        "print(\"Downloading... This may take a couple of minutes.\")\n",
        "fname = wget.download(url)\n",
        "\n",
        "print(\"The file \", fname, \" has successfully been downloaded!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDppDUtb3ISx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder_name = \"data\"\n",
        "\n",
        "print(os.getcwd())\n",
        "if os.path.exists(os.path.join(main_path, project_dir, data_folder_name)) is not True:\n",
        "    os.makedirs(os.path.join(main_path, project_dir, data_folder_name))\n",
        "\n",
        "with zipfile.ZipFile(fname, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(data_folder_name)\n",
        "\n",
        "print(\"Files unzipped!\")\n",
        "\n",
        "os.remove(fname)\n",
        "os.chdir(main_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaZ2PxkD2QyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ######## MOVING FILES INTO TRAIN DIRECTORY ########\n",
        "\n",
        "# The DeepReg Dataloaders require some specific folder structure, which we make now\n",
        "! pwd\n",
        "project_dir = \"demos/unpaired_ct_lung\"\n",
        "path_to_data_folder = os.path.join(main_path, project_dir, data_folder_name)\n",
        "path_to_train = os.path.join(main_path, project_dir, data_folder_name, \"train\")\n",
        "path_to_test = os.path.join(main_path, project_dir, data_folder_name, \"test\")\n",
        "path_to_images_and_labels = os.path.join(\n",
        "    main_path, project_dir, data_folder_name, \"training\"\n",
        ")\n",
        "\n",
        "labels_fnames = os.listdir(os.path.join(path_to_images_and_labels, \"lungMasks\"))\n",
        "images_fnames = os.listdir(os.path.join(path_to_images_and_labels, \"scans\"))\n",
        "\n",
        "if os.path.exists(path_to_train) is not True:\n",
        "    os.makedirs(path_to_train)\n",
        "    os.makedirs(os.path.join(path_to_train, \"fixed_images\"))\n",
        "    os.makedirs(os.path.join(path_to_train, \"fixed_labels\"))\n",
        "    os.makedirs(os.path.join(path_to_train, \"moving_images\"))\n",
        "    os.makedirs(os.path.join(path_to_train, \"moving_labels\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJrA7D3A34ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moveFilesIntoCorrectPath(\n",
        "    fnames, path_to_images_and_labels, new_path, suffix, sub_folder_name\n",
        "):\n",
        "    os.chdir(os.path.join(path_to_images_and_labels, sub_folder_name))\n",
        "    for file in fnames:\n",
        "        if \"insp\" in file:\n",
        "            source = file\n",
        "            destination = os.path.join(path_to_train, \"fixed_\" + suffix)\n",
        "            shutil.move(source, destination)\n",
        "        if \"exp\" in file:\n",
        "            source = file\n",
        "            destination = os.path.join(path_to_train, \"moving_\" + suffix)\n",
        "            shutil.move(source, destination)\n",
        "\n",
        "\n",
        "if os.path.exists(path_to_images_and_labels):\n",
        "\n",
        "    moveFilesIntoCorrectPath(\n",
        "        images_fnames, path_to_images_and_labels, path_to_train, \"images\", \"scans\"\n",
        "    )\n",
        "    moveFilesIntoCorrectPath(\n",
        "        labels_fnames, path_to_images_and_labels, path_to_train, \"labels\", \"lungMasks\"\n",
        "    )\n",
        "\n",
        "os.chdir(main_path)\n",
        "\n",
        "######## MOVING FILES INTO TEST AND VALID DIRECTORY ########\n",
        "\n",
        "path_to_test = os.path.join(path_to_data_folder, \"test\")\n",
        "path_to_valid = os.path.join(path_to_data_folder, \"valid\")\n",
        "\n",
        "if os.path.exists(path_to_test) is not True:\n",
        "\n",
        "    os.mkdir(path_to_test)\n",
        "    os.mkdir(os.path.join(path_to_test, \"fixed_images\"))\n",
        "    os.mkdir(os.path.join(path_to_test, \"fixed_labels\"))\n",
        "    os.mkdir(os.path.join(path_to_test, \"moving_images\"))\n",
        "    os.mkdir(os.path.join(path_to_test, \"moving_labels\"))\n",
        "\n",
        "    ratio_of_test_and_valid_samples = 0.2\n",
        "\n",
        "    unique_case_names = []\n",
        "    for file in images_fnames:\n",
        "        case_name_as_list = file.split(\"_\")[0:2]\n",
        "        case_name = case_name_as_list[0] + \"_\" + case_name_as_list[1]\n",
        "        unique_case_names.append(case_name)\n",
        "    unique_case_names = np.unique(unique_case_names)\n",
        "\n",
        "    test_and_valid_cases = random.sample(\n",
        "        list(unique_case_names),\n",
        "        int(ratio_of_test_and_valid_samples * len(unique_case_names)),\n",
        "    )\n",
        "    test_cases = test_and_valid_cases[\n",
        "        0 : int(int(ratio_of_test_and_valid_samples * len(unique_case_names) / 2))\n",
        "    ]\n",
        "    valid_cases = test_and_valid_cases[\n",
        "        int(int(ratio_of_test_and_valid_samples * len(unique_case_names) / 2)) + 1 :\n",
        "    ]\n",
        "\n",
        "    def moveTestCasesIntoCorrectPath(test_cases, path_to_train, path_to_test):\n",
        "        folder_names = os.listdir(path_to_train)\n",
        "        os.chdir(path_to_train)\n",
        "        for case in test_cases:\n",
        "            for folder in folder_names:\n",
        "                file_names = os.listdir(os.path.join(path_to_train, folder))\n",
        "                for file in file_names:\n",
        "                    if case in file:\n",
        "                        os.chdir(os.path.join(path_to_train, folder))\n",
        "                        source = file\n",
        "                        destination = os.path.join(path_to_test, folder)\n",
        "                        shutil.move(source, destination)\n",
        "\n",
        "    moveTestCasesIntoCorrectPath(test_cases, path_to_train, path_to_test)\n",
        "\n",
        "    os.mkdir(path_to_valid)\n",
        "    os.mkdir(os.path.join(path_to_valid, \"fixed_images\"))\n",
        "    os.mkdir(os.path.join(path_to_valid, \"fixed_labels\"))\n",
        "    os.mkdir(os.path.join(path_to_valid, \"moving_images\"))\n",
        "    os.mkdir(os.path.join(path_to_valid, \"moving_labels\"))\n",
        "\n",
        "    moveTestCasesIntoCorrectPath(valid_cases, path_to_train, path_to_valid)\n",
        "\n",
        "######## NAMING FILES SUCH THAT THEIR NAMES MATCH FOR PAIRING ########\n",
        "\n",
        "# name all files such that names match exactly for training\n",
        "\n",
        "for folder in os.listdir(path_to_train):\n",
        "    path_to_folder = os.path.join(path_to_train, folder)\n",
        "    os.chdir(path_to_folder)\n",
        "    for file in os.listdir(path_to_folder):\n",
        "        if \"_insp\" in file:\n",
        "            new_name = file.replace(\"_insp\", \"\")\n",
        "        elif \"_exp\" in file:\n",
        "            new_name = file.replace(\"_exp\", \"\")\n",
        "        source = file\n",
        "        destination = new_name\n",
        "        os.rename(source, destination)\n",
        "\n",
        "# name all files such that names match exactly for testing\n",
        "\n",
        "for folder in os.listdir(path_to_test):\n",
        "    path_to_folder = os.path.join(path_to_test, folder)\n",
        "    os.chdir(path_to_folder)\n",
        "    for file in os.listdir(path_to_folder):\n",
        "        if \"_insp\" in file:\n",
        "            new_name = file.replace(\"_insp\", \"\")\n",
        "        elif \"_exp\" in file:\n",
        "            new_name = file.replace(\"_exp\", \"\")\n",
        "        source = file\n",
        "        destination = new_name\n",
        "        os.rename(source, destination)\n",
        "\n",
        "# name all files such that names match exactly for validation\n",
        "\n",
        "for folder in os.listdir(path_to_valid):\n",
        "    path_to_folder = os.path.join(path_to_valid, folder)\n",
        "    os.chdir(path_to_folder)\n",
        "    for file in os.listdir(path_to_folder):\n",
        "        if \"_insp\" in file:\n",
        "            new_name = file.replace(\"_insp\", \"\")\n",
        "        elif \"_exp\" in file:\n",
        "            new_name = file.replace(\"_exp\", \"\")\n",
        "        source = file\n",
        "        destination = new_name\n",
        "        os.rename(source, destination)\n",
        "\n",
        "shutil.rmtree(os.path.join(path_to_images_and_labels))\n",
        "os.chdir(main_path)\n",
        "\n",
        "######## FOR UNPAIRED WE USE IMAMGES FROM ONE TIMEPOINT ONLY ########\n",
        "\n",
        "# so now remove fixed_images and fixed_labels\n",
        "# and rename moving_images to images\n",
        "# and moving_labels to labels\n",
        "\n",
        "folders = os.listdir(os.path.join(project_dir, data_folder_name))\n",
        "\n",
        "for folder in folders:\n",
        "    shutil.rmtree(os.path.join(project_dir, data_folder_name, folder, \"fixed_images\"))\n",
        "    shutil.rmtree(os.path.join(project_dir, data_folder_name, folder, \"fixed_labels\"))\n",
        "    os.rename(\n",
        "        os.path.join(project_dir, data_folder_name, folder, \"moving_images\"),\n",
        "        os.path.join(project_dir, data_folder_name, folder, \"images\"),\n",
        "    )\n",
        "    os.rename(\n",
        "        os.path.join(project_dir, data_folder_name, folder, \"moving_labels\"),\n",
        "        os.path.join(project_dir, data_folder_name, folder, \"labels\"),\n",
        "    )\n",
        "\n",
        "print(\"All files moved and restructured\")\n",
        "\n",
        "os.chdir(main_path)\n",
        "\n",
        "######## NOW WE RESACLE THE IMAGES TO 255 ########\n",
        "\n",
        "data_dir = r\"demos/unpaired_ct_lung/data\"\n",
        "folders = os.listdir(data_dir)\n",
        "\n",
        "for folder in folders:\n",
        "    subfolders = os.listdir(os.path.join(data_dir, folder))\n",
        "    print(\"\\n Working on \", folder, \", progress:\")\n",
        "    for subfolder in tqdm(subfolders):\n",
        "        files = os.listdir(os.path.join(data_dir, folder, subfolder))\n",
        "        for file in files:\n",
        "            if file.startswith(\"case_020\"):  # this case did not laod correctly\n",
        "                os.remove(os.path.join(data_dir, folder, subfolder, file))\n",
        "            else:\n",
        "                im_data = np.asarray(\n",
        "                    nib.load(os.path.join(data_dir, folder, subfolder, file)).dataobj,\n",
        "                    dtype=np.float32,\n",
        "                )\n",
        "                if np.max(im_data) > 255.0:\n",
        "                    im_data = ((im_data + 285) / (3770 + 285)) * 255.0  # rescale image\n",
        "                    img = nib.Nifti1Image(im_data, affine=None)\n",
        "                    nib.save(img, os.path.join(data_dir, folder, subfolder, file))\n",
        "                    if np.max(img.dataobj) > 255.0:\n",
        "                        print(\n",
        "                            \"Recheck the following file: \",\n",
        "                            os.path.join(data_dir, folder, subfolder, file),\n",
        "                        )\n",
        "                    nib.save(img, os.path.join(data_dir, folder, subfolder, file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJmrcRhh5RpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deepreg.train import train\n",
        "! ls\n",
        "! pwd\n",
        "\n",
        "######## NOW WE DO THE TRAINING ########\n",
        "import tensorflow as tf\n",
        "gpu = tf.test.gpu_device_name()\n",
        "gpu_allow_growth = True\n",
        "ckpt_path = \"\"\n",
        "log_dir = \"learn2reg_t2_unpaired_train_logs\"\n",
        "\n",
        "config_path = [\n",
        "    os.path.join(os.getcwd(), \"deepreg/config/test/ddf.yaml\"),\n",
        "     os.path.join(os.getcwd(), \"demos/unpaired_ct_lung/unpaired_ct_lung.yaml\")\n",
        "]\n",
        "\n",
        "# We use\n",
        "train(\n",
        "    gpu=gpu,\n",
        "    config_path=config_path,\n",
        "    gpu_allow_growth=gpu_allow_growth,\n",
        "    ckpt_path=ckpt_path,\n",
        "    log_dir=log_dir,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHv3Pidn5XKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from deepreg.predict import predict\n",
        "\n",
        "######## PREDICTION ########\n",
        "\n",
        "log_dir = \"learn2reg_t2_unpaired_train_logs\"\n",
        "ckpt_path = os.path.join(\"logs\", log_dir, \"save\", \"weights-epoch2.ckpt\")\n",
        "\n",
        "gpu = \"\"\n",
        "gpu_allow_growth = False\n",
        "predict(\n",
        "    gpu=gpu,\n",
        "    gpu_allow_growth=gpu_allow_growth,\n",
        "    ckpt_path=ckpt_path,\n",
        "    mode=\"test\",\n",
        "    batch_size=1,\n",
        "    log_dir=log_dir,\n",
        "    sample_label=\"all\",\n",
        ")\n",
        "\n",
        "# the numerical metrics are saved in the logs directory specified\n",
        "\n",
        "######## VISUALISATION ########\n",
        "\n",
        "# Now lets load in a few samples from the predicitons and plot them\n",
        "\n",
        "# change the following line to the path to image0 label0\n",
        "path_to_image0_label0 = r\"\"\n",
        "os.chdir(path_to_image0_label0)\n",
        "\n",
        "# change image names if different images need to be plotted instead\n",
        "\n",
        "plt.subplot(3, 2, 1)\n",
        "label144 = plt.imread(\"depth144_fixed_label.png\")\n",
        "plt.imshow(label144)\n",
        "plt.title(\"Label\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "pred144 = plt.imread(\"depth144_fixed_pred.png\")\n",
        "plt.imshow(pred144)\n",
        "plt.title(\"Prediction\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "\n",
        "plt.subplot(3, 2, 3)\n",
        "label145 = plt.imread(\"depth145_fixed_label.png\")\n",
        "plt.imshow(label145)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "pred145 = plt.imread(\"depth145_fixed_pred.png\")\n",
        "plt.imshow(pred145)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "\n",
        "plt.subplot(3, 2, 5)\n",
        "label184 = plt.imread(\"depth184_fixed_label.png\")\n",
        "plt.imshow(label184)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "pred184 = plt.imread(\"depth184_fixed_pred.png\")\n",
        "plt.imshow(pred184)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# this is the path where you want to save the visualisation as a png\n",
        "path_to_save_fig = r\"\"\n",
        "plt.savefig(os.path.join(path_to_save_fig, \"labels_and_preds.png\"))\n",
        "\n",
        "print(\"Visual representation of predictions saved to path specified\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
