dataset:
  dir:
    train:
      - "demos/unpaired_us_prostate_cv/dataset/fold0"
      - "demos/unpaired_us_prostate_cv/dataset/fold1"
      - "demos/unpaired_us_prostate_cv/dataset/fold2"
      - "demos/unpaired_us_prostate_cv/dataset/fold3"
      - "demos/unpaired_us_prostate_cv/dataset/fold4"
      - "demos/unpaired_us_prostate_cv/dataset/fold5"
      - "demos/unpaired_us_prostate_cv/dataset/fold6"
      - "demos/unpaired_us_prostate_cv/dataset/fold7"
    valid: "demos/unpaired_us_prostate_cv/dataset/fold8"
    test: "demos/unpaired_us_prostate_cv/dataset/fold9"
  format: "h5"
  type: "unpaired" # paired / unpaired / grouped
  labeled: false
  image_shape: [64, 100, 100]
train:
  # define neural network structure
  method: "ddf" # the registration method, value should be ddf / dvf / conditional
  backbone:
    name: "local" # value should be local / global / unet
    num_channel_initial: 16 # number of initial channel in local net, controls the size of the network
    extract_levels: [0, 1, 2, 3]

  # define the loss function for training
  loss:
    dissimilarity:
      image:
        name: "ssd"
        weight: 0.1
      label:
        weight: 1.0
        name: "dice"
        scales: [0, 1, 2, 4, 8, 16]
    regularization:
      weight: 10.0 # weight of regularization loss
      name: "bending" # options include "bending", "gradient"

  # define the optimizer
  optimizer:
    name: "adam" # value should be adam / sgd / rms
    adam:
      learning_rate: 1.0e-5
    sgd:
      learning_rate: 1.0e-4
      momentum: 0.9
    rms:
      learning_rate: 1.0e-4
      momentum: 0.9

  # define the hyper-parameters for preprocessing
  preprocess:
    batch_size: 6
    shuffle_buffer_num_batch: 1 # shuffle_buffer_size = batch_size * shuffle_buffer_num_batch

  # other training hyper-parameters
  epochs: 5000 # number of training epochs
  save_period: 100 # the model will be saved every `save_period` epochs.
